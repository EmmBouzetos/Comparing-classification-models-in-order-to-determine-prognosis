{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "wchOUUsrO3yP"
      },
      "outputs": [],
      "source": [
        "# all the inmports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "count_data_path=(r'C:\\Users\\manos\\OneDrive - Vrije Universiteit Amsterdam\\VU\\ML\\TCGA_dataset\\TCGA_dataset\\tcga_rna_count_data_crc.csv') \n",
        "prediction_data_path=(r'C:\\Users\\manos\\OneDrive - Vrije Universiteit Amsterdam\\VU\\ML\\TCGA_dataset\\TCGA_dataset\\prediction_file_crc.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "FLYde1LsPZ1T"
      },
      "outputs": [],
      "source": [
        "count_df=pd.read_csv(count_data_path)\n",
        "pred_df=pd.read_csv(prediction_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BECd_LOQZ4J",
        "outputId": "9d9236a6-236b-41db-cf91-ff84bdd1ec41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSS              63.419913\n",
            "MSI-L            15.800866\n",
            "MSI-H            14.935065\n",
            "Indeterminate     0.432900\n",
            "Name: msi_status, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "value_counts=pred_df['msi_status'].value_counts()\n",
        "percentage= value_counts/len(pred_df)*100\n",
        "print(percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7BtvmvaUEx4"
      },
      "source": [
        "Convert the MSI-H and MSI_L to MSI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "43ZbbE0XQs5s"
      },
      "outputs": [],
      "source": [
        "pred_df['msi_status']=pred_df['msi_status'].replace({'MSI-H':0, \"MSI-L\": 1,'MSS':1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T0K7JDV8pB5"
      },
      "source": [
        "Categorical to numerical MSI=0 , MSS=1 (BINARY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC1_RDQ28_Oy",
        "outputId": "0f981317-4424-4d86-c1ac-731322791906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1                79.220779\n",
            "0                14.935065\n",
            "Indeterminate     0.432900\n",
            "Name: msi_status, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "value_counts=pred_df['msi_status'].value_counts()\n",
        "percentage= value_counts/len(pred_df)*100\n",
        "print(percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZwaFD38GUBh"
      },
      "source": [
        "Remove Indeterminate & unknown Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "-QhfdS9JGTSV"
      },
      "outputs": [],
      "source": [
        "pred_df = pred_df[pred_df['msi_status'] != 'Indeterminate']\n",
        "pred_df = pred_df[pred_df['msi_status'].isin([0,1])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6Zgo7kVIDPi"
      },
      "source": [
        "Get dumies to convert categorical to numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "QCWTYXXCIB8b"
      },
      "outputs": [],
      "source": [
        "pred_df_num = pd.get_dummies(pred_df, columns=['TP53'])\n",
        "pred_df_num = pd.get_dummies(pred_df_num, columns=['KRAS'])\n",
        "pred_df_num = pd.get_dummies(pred_df_num, columns=['BRAF'])\n",
        "pred_df_num = pd.get_dummies(pred_df_num, columns=['APC'])\n",
        "pred_df_num = pd.get_dummies(pred_df_num, columns=['TTN'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLAdm3je-a_J"
      },
      "source": [
        "Enumarate Sample ids  in a dictionary save the dict in a file replace ids with keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "2A3n34Yi-AW5"
      },
      "outputs": [],
      "source": [
        "id_to_num = {}\n",
        "for i, id in enumerate(pred_df_num['Unnamed: 0'].unique()):\n",
        "    id_to_num[id] = i\n",
        "\n",
        "# Save the dictionary to a file\n",
        "import json\n",
        "with open('id_to_num.json', 'w') as f:\n",
        "    json.dump(id_to_num, f)\n",
        "\n",
        "# Replace the IDs with the corresponding numbers in the DataFrame\n",
        "pred_df_num['Unnamed: 0'] = pred_df_num['Unnamed: 0'].map(id_to_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "7ctEmDOvIR_Y",
        "outputId": "1b91d490-c83b-4383-e745-e7b34e864ee7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TBL</th>\n",
              "      <th>msi_status</th>\n",
              "      <th>fraction_genome_altered</th>\n",
              "      <th>aneuploidy_score</th>\n",
              "      <th>TMB</th>\n",
              "      <th>TP53_SNV</th>\n",
              "      <th>TP53_WT</th>\n",
              "      <th>KRAS_SNV</th>\n",
              "      <th>KRAS_WT</th>\n",
              "      <th>BRAF_SNV</th>\n",
              "      <th>BRAF_WT</th>\n",
              "      <th>APC_SNV</th>\n",
              "      <th>APC_WT</th>\n",
              "      <th>TTN_SNV</th>\n",
              "      <th>TTN_WT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114119</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>0.311631</td>\n",
              "      <td>12</td>\n",
              "      <td>81</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.422921</td>\n",
              "      <td>13</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.357734</td>\n",
              "      <td>12</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.049432</td>\n",
              "      <td>2</td>\n",
              "      <td>1828</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>430</td>\n",
              "      <td>104</td>\n",
              "      <td>1</td>\n",
              "      <td>0.309643</td>\n",
              "      <td>9</td>\n",
              "      <td>209</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>431</td>\n",
              "      <td>105</td>\n",
              "      <td>1</td>\n",
              "      <td>0.270808</td>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>432</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>0.408573</td>\n",
              "      <td>15</td>\n",
              "      <td>143</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>433</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>0.178141</td>\n",
              "      <td>6</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>434</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0.012669</td>\n",
              "      <td>0</td>\n",
              "      <td>2437</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>435 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  TBL msi_status  fraction_genome_altered  aneuploidy_score  \\\n",
              "0             0   19          1                 0.114119                 6   \n",
              "1             1   38          1                 0.311631                12   \n",
              "3             2   87          1                 0.422921                13   \n",
              "4             3   28          1                 0.357734                12   \n",
              "5             4    3          0                 0.049432                 2   \n",
              "..          ...  ...        ...                      ...               ...   \n",
              "457         430  104          1                 0.309643                 9   \n",
              "458         431  105          1                 0.270808                10   \n",
              "459         432   82          1                 0.408573                15   \n",
              "460         433  115          1                 0.178141                 6   \n",
              "461         434   28          0                 0.012669                 0   \n",
              "\n",
              "      TMB  TP53_SNV  TP53_WT  KRAS_SNV  KRAS_WT  BRAF_SNV  BRAF_WT  APC_SNV  \\\n",
              "0     118         0        1         0        1         1        0        1   \n",
              "1      81         1        0         1        0         0        1        0   \n",
              "3     159         1        0         1        0         0        1        1   \n",
              "4      72         1        0         0        1         0        1        1   \n",
              "5    1828         0        1         1        0         0        1        1   \n",
              "..    ...       ...      ...       ...      ...       ...      ...      ...   \n",
              "457   209         1        0         1        0         0        1        1   \n",
              "458   115         1        0         0        1         0        1        1   \n",
              "459   143         1        0         1        0         0        1        1   \n",
              "460   150         1        0         0        1         0        1        0   \n",
              "461  2437         1        0         0        1         0        1        1   \n",
              "\n",
              "     APC_WT  TTN_SNV  TTN_WT  \n",
              "0         0        0       1  \n",
              "1         1        0       1  \n",
              "3         0        1       0  \n",
              "4         0        0       1  \n",
              "5         0        1       0  \n",
              "..      ...      ...     ...  \n",
              "457       0        1       0  \n",
              "458       0        0       1  \n",
              "459       0        0       1  \n",
              "460       1        0       1  \n",
              "461       0        1       0  \n",
              "\n",
              "[435 rows x 16 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_df_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj8cfUyi9uxn"
      },
      "source": [
        "Balancing (Requires further exploration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "htHSt8oc9ejZ"
      },
      "outputs": [],
      "source": [
        "# from imblearn.over_sampling import SMOTE\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# # Separate majority and minority classes\n",
        "# majority_class = pred_df_num[pred_df_num['msi_status'] == 1]\n",
        "# minority_class = pred_df_num[pred_df_num['msi_status'] == 0]\n",
        "\n",
        "# # Remove unknown and intermediate values from minority class\n",
        "# minority_class = minority_class[minority_class['msi_status'].isin([0,1])]\n",
        "\n",
        "# # Apply SMOTE oversampling to minority class\n",
        "# oversampler = SMOTE(random_state=42)\n",
        "# minority_oversampled, minority_labels_oversampled = oversampler.fit_resample(minority_class.drop('msi_status', axis=1), minority_class['msi_status'])\n",
        "\n",
        "# # Apply RandomUnderSampler to majority class\n",
        "# undersampler = RandomUnderSampler(random_state=42)\n",
        "# majority_undersampled, majority_labels_undersampled = undersampler.fit_resample(majority_class.drop('msi_status', axis=1), majority_class['msi_status'])\n",
        "\n",
        "# # Combine oversampled and undersampled data\n",
        "# df_balanced = pd.concat([majority_undersampled, minority_oversampled])\n",
        "# df_balanced['msi_status'] = pd.concat([majority_labels_undersampled, minority_labels_oversampled])\n",
        "\n",
        "# # Verify the class distribution of the balanced data\n",
        "# print(df_balanced['msi_status'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsfi_yv6EcZs"
      },
      "source": [
        "# **Prepro Count Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1OrceG5Fto8"
      },
      "source": [
        "Remove Genes with Zero counts in all Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "HVijKOw8Fs_C"
      },
      "outputs": [],
      "source": [
        "# Check which genes have zero counts in all samples\n",
        "zero_count_genes = count_df.columns[count_df.eq(0).all(axis=0)]\n",
        "\n",
        "# Remove genes with zero counts from dataframe\n",
        "count_df = count_df.drop(columns=zero_count_genes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "UV8YlBS3GDUp",
        "outputId": "5657155d-edad-4bf3-c684-756a03ee7922"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TCGA-CK-5912-01A</th>\n",
              "      <th>TCGA-QG-A5Z2-01A</th>\n",
              "      <th>TCGA-AG-3898-01A</th>\n",
              "      <th>TCGA-G4-6299-01A</th>\n",
              "      <th>TCGA-AG-4008-01A</th>\n",
              "      <th>TCGA-NH-A8F8-01A</th>\n",
              "      <th>TCGA-AD-6548-01A</th>\n",
              "      <th>TCGA-AA-A02Y-01A</th>\n",
              "      <th>TCGA-EI-6514-01A</th>\n",
              "      <th>...</th>\n",
              "      <th>TCGA-CL-5918-01A</th>\n",
              "      <th>TCGA-AG-A01Y-01A</th>\n",
              "      <th>TCGA-AG-A014-01A</th>\n",
              "      <th>TCGA-AG-A016-01A</th>\n",
              "      <th>TCGA-AA-3846-01A</th>\n",
              "      <th>TCGA-CA-5797-01A</th>\n",
              "      <th>TCGA-AA-3860-01A</th>\n",
              "      <th>TCGA-CK-4951-01A</th>\n",
              "      <th>TCGA-EI-6507-01A</th>\n",
              "      <th>TCGA-AA-3858-01A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ND4</td>\n",
              "      <td>282779</td>\n",
              "      <td>527763</td>\n",
              "      <td>351929</td>\n",
              "      <td>287719</td>\n",
              "      <td>190175</td>\n",
              "      <td>534458</td>\n",
              "      <td>258680</td>\n",
              "      <td>609116</td>\n",
              "      <td>1788482</td>\n",
              "      <td>...</td>\n",
              "      <td>967151</td>\n",
              "      <td>253949</td>\n",
              "      <td>357582</td>\n",
              "      <td>193103</td>\n",
              "      <td>378175</td>\n",
              "      <td>241368</td>\n",
              "      <td>174340</td>\n",
              "      <td>344243</td>\n",
              "      <td>187689</td>\n",
              "      <td>120685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COX1</td>\n",
              "      <td>174425</td>\n",
              "      <td>550980</td>\n",
              "      <td>221923</td>\n",
              "      <td>77856</td>\n",
              "      <td>126014</td>\n",
              "      <td>573269</td>\n",
              "      <td>334800</td>\n",
              "      <td>988344</td>\n",
              "      <td>882782</td>\n",
              "      <td>...</td>\n",
              "      <td>503826</td>\n",
              "      <td>178148</td>\n",
              "      <td>277609</td>\n",
              "      <td>169953</td>\n",
              "      <td>328256</td>\n",
              "      <td>270218</td>\n",
              "      <td>159090</td>\n",
              "      <td>244393</td>\n",
              "      <td>186843</td>\n",
              "      <td>113810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COX2</td>\n",
              "      <td>215346</td>\n",
              "      <td>455961</td>\n",
              "      <td>219310</td>\n",
              "      <td>224206</td>\n",
              "      <td>121250</td>\n",
              "      <td>539229</td>\n",
              "      <td>239678</td>\n",
              "      <td>729632</td>\n",
              "      <td>770006</td>\n",
              "      <td>...</td>\n",
              "      <td>688044</td>\n",
              "      <td>100534</td>\n",
              "      <td>233873</td>\n",
              "      <td>148345</td>\n",
              "      <td>196468</td>\n",
              "      <td>253742</td>\n",
              "      <td>107697</td>\n",
              "      <td>196681</td>\n",
              "      <td>104451</td>\n",
              "      <td>99580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COX3</td>\n",
              "      <td>215935</td>\n",
              "      <td>224912</td>\n",
              "      <td>194021</td>\n",
              "      <td>249685</td>\n",
              "      <td>163588</td>\n",
              "      <td>640377</td>\n",
              "      <td>215029</td>\n",
              "      <td>496405</td>\n",
              "      <td>509296</td>\n",
              "      <td>...</td>\n",
              "      <td>656321</td>\n",
              "      <td>119946</td>\n",
              "      <td>133931</td>\n",
              "      <td>76543</td>\n",
              "      <td>247324</td>\n",
              "      <td>265639</td>\n",
              "      <td>130445</td>\n",
              "      <td>200891</td>\n",
              "      <td>90755</td>\n",
              "      <td>137800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACTB</td>\n",
              "      <td>114483</td>\n",
              "      <td>273373</td>\n",
              "      <td>111800</td>\n",
              "      <td>266851</td>\n",
              "      <td>94666</td>\n",
              "      <td>199718</td>\n",
              "      <td>508419</td>\n",
              "      <td>342245</td>\n",
              "      <td>275784</td>\n",
              "      <td>...</td>\n",
              "      <td>264552</td>\n",
              "      <td>123410</td>\n",
              "      <td>150556</td>\n",
              "      <td>171336</td>\n",
              "      <td>90398</td>\n",
              "      <td>371604</td>\n",
              "      <td>124204</td>\n",
              "      <td>210810</td>\n",
              "      <td>235117</td>\n",
              "      <td>150755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33374</th>\n",
              "      <td>PRAMEF13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33375</th>\n",
              "      <td>OR8B4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33376</th>\n",
              "      <td>OR1S1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33377</th>\n",
              "      <td>PRAMEF26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33378</th>\n",
              "      <td>DUX4L25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33379 rows × 463 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  TCGA-CK-5912-01A  TCGA-QG-A5Z2-01A  TCGA-AG-3898-01A  \\\n",
              "0            ND4            282779            527763            351929   \n",
              "1           COX1            174425            550980            221923   \n",
              "2           COX2            215346            455961            219310   \n",
              "3           COX3            215935            224912            194021   \n",
              "4           ACTB            114483            273373            111800   \n",
              "...          ...               ...               ...               ...   \n",
              "33374   PRAMEF13                 0                 0                 0   \n",
              "33375      OR8B4                 0                 0                 0   \n",
              "33376      OR1S1                 0                 0                 0   \n",
              "33377   PRAMEF26                 0                 0                 0   \n",
              "33378    DUX4L25                 0                 0                 0   \n",
              "\n",
              "       TCGA-G4-6299-01A  TCGA-AG-4008-01A  TCGA-NH-A8F8-01A  TCGA-AD-6548-01A  \\\n",
              "0                287719            190175            534458            258680   \n",
              "1                 77856            126014            573269            334800   \n",
              "2                224206            121250            539229            239678   \n",
              "3                249685            163588            640377            215029   \n",
              "4                266851             94666            199718            508419   \n",
              "...                 ...               ...               ...               ...   \n",
              "33374                 0                 0                 0                 0   \n",
              "33375                 0                 0                 0                 0   \n",
              "33376                 0                 0                 0                 0   \n",
              "33377                 0                 0                 0                 0   \n",
              "33378                 0                 0                 0                 0   \n",
              "\n",
              "       TCGA-AA-A02Y-01A  TCGA-EI-6514-01A  ...  TCGA-CL-5918-01A  \\\n",
              "0                609116           1788482  ...            967151   \n",
              "1                988344            882782  ...            503826   \n",
              "2                729632            770006  ...            688044   \n",
              "3                496405            509296  ...            656321   \n",
              "4                342245            275784  ...            264552   \n",
              "...                 ...               ...  ...               ...   \n",
              "33374                 0                 0  ...                 0   \n",
              "33375                 0                 0  ...                 0   \n",
              "33376                 0                 0  ...                 0   \n",
              "33377                 0                 0  ...                 0   \n",
              "33378                 0                 0  ...                 0   \n",
              "\n",
              "       TCGA-AG-A01Y-01A  TCGA-AG-A014-01A  TCGA-AG-A016-01A  TCGA-AA-3846-01A  \\\n",
              "0                253949            357582            193103            378175   \n",
              "1                178148            277609            169953            328256   \n",
              "2                100534            233873            148345            196468   \n",
              "3                119946            133931             76543            247324   \n",
              "4                123410            150556            171336             90398   \n",
              "...                 ...               ...               ...               ...   \n",
              "33374                 0                 0                 0                 0   \n",
              "33375                 0                 0                 0                 0   \n",
              "33376                 0                 0                 0                 0   \n",
              "33377                 0                 0                 0                 0   \n",
              "33378                 0                 0                 0                 0   \n",
              "\n",
              "       TCGA-CA-5797-01A  TCGA-AA-3860-01A  TCGA-CK-4951-01A  TCGA-EI-6507-01A  \\\n",
              "0                241368            174340            344243            187689   \n",
              "1                270218            159090            244393            186843   \n",
              "2                253742            107697            196681            104451   \n",
              "3                265639            130445            200891             90755   \n",
              "4                371604            124204            210810            235117   \n",
              "...                 ...               ...               ...               ...   \n",
              "33374                 0                 0                 0                 0   \n",
              "33375                 0                 0                 0                 0   \n",
              "33376                 0                 0                 0                 0   \n",
              "33377                 0                 0                 0                 0   \n",
              "33378                 0                 0                 0                 0   \n",
              "\n",
              "       TCGA-AA-3858-01A  \n",
              "0                120685  \n",
              "1                113810  \n",
              "2                 99580  \n",
              "3                137800  \n",
              "4                150755  \n",
              "...                 ...  \n",
              "33374                 0  \n",
              "33375                 0  \n",
              "33376                 0  \n",
              "33377                 0  \n",
              "33378                 0  \n",
              "\n",
              "[33379 rows x 463 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzrtTUe_FPDB"
      },
      "source": [
        " Remove POLE POLD genes from count data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "rqxTgbYuExHY"
      },
      "outputs": [],
      "source": [
        "count_df_01 = count_df[count_df.iloc[:,0] != 'POLE']\n",
        "count_df_02 = count_df_01[count_df_01.iloc[:,0] != 'POLD1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Z0fGlN4tD0Pk"
      },
      "outputs": [],
      "source": [
        "count_df_norm=count_df_02.iloc[:,1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ie0GRMDDkmS"
      },
      "source": [
        "One common normalization technique for RNA-seq data is called \"library size normalization\". This involves dividing the raw counts of each sample by the total number of reads in that sample, and then multiplying the result by a scaling factor (e.g., 1 million) to get \"counts per million\" (CPM) or \"reads per million\" (RPM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "8R37StNC-f_A"
      },
      "outputs": [],
      "source": [
        "# Calculate library sizes (total number of reads) for each sample\n",
        "library_sizes = count_df_norm.sum(axis=0)\n",
        "\n",
        "# Normalize counts by library size and scale to CPM\n",
        "cpm_df = count_df_norm.divide(library_sizes, axis=1) * 1e6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QfcOO8eLVEj"
      },
      "source": [
        "add back the names of the genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "CjRus8KILUGj"
      },
      "outputs": [],
      "source": [
        "# Get the names of the genes\n",
        "gene_names = count_df_02.iloc[:, 0]\n",
        "\n",
        "# Insert the gene names at the beginning of the cpm_df dataframe\n",
        "cpm_df.insert(loc=0, column='Gene Name', value=gene_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "_F1_STPvNebh",
        "outputId": "35b01b49-fec0-49f4-f33b-ca0fb775f18b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TBL</th>\n",
              "      <th>msi_status</th>\n",
              "      <th>fraction_genome_altered</th>\n",
              "      <th>aneuploidy_score</th>\n",
              "      <th>TMB</th>\n",
              "      <th>TP53_SNV</th>\n",
              "      <th>TP53_WT</th>\n",
              "      <th>KRAS_SNV</th>\n",
              "      <th>KRAS_WT</th>\n",
              "      <th>BRAF_SNV</th>\n",
              "      <th>BRAF_WT</th>\n",
              "      <th>APC_SNV</th>\n",
              "      <th>APC_WT</th>\n",
              "      <th>TTN_SNV</th>\n",
              "      <th>TTN_WT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114119</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>0.311631</td>\n",
              "      <td>12</td>\n",
              "      <td>81</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.422921</td>\n",
              "      <td>13</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>0.357734</td>\n",
              "      <td>12</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.049432</td>\n",
              "      <td>2</td>\n",
              "      <td>1828</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>430</td>\n",
              "      <td>104</td>\n",
              "      <td>1</td>\n",
              "      <td>0.309643</td>\n",
              "      <td>9</td>\n",
              "      <td>209</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>431</td>\n",
              "      <td>105</td>\n",
              "      <td>1</td>\n",
              "      <td>0.270808</td>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>432</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>0.408573</td>\n",
              "      <td>15</td>\n",
              "      <td>143</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>433</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>0.178141</td>\n",
              "      <td>6</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>434</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0.012669</td>\n",
              "      <td>0</td>\n",
              "      <td>2437</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>435 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  TBL msi_status  fraction_genome_altered  aneuploidy_score  \\\n",
              "0             0   19          1                 0.114119                 6   \n",
              "1             1   38          1                 0.311631                12   \n",
              "3             2   87          1                 0.422921                13   \n",
              "4             3   28          1                 0.357734                12   \n",
              "5             4    3          0                 0.049432                 2   \n",
              "..          ...  ...        ...                      ...               ...   \n",
              "457         430  104          1                 0.309643                 9   \n",
              "458         431  105          1                 0.270808                10   \n",
              "459         432   82          1                 0.408573                15   \n",
              "460         433  115          1                 0.178141                 6   \n",
              "461         434   28          0                 0.012669                 0   \n",
              "\n",
              "      TMB  TP53_SNV  TP53_WT  KRAS_SNV  KRAS_WT  BRAF_SNV  BRAF_WT  APC_SNV  \\\n",
              "0     118         0        1         0        1         1        0        1   \n",
              "1      81         1        0         1        0         0        1        0   \n",
              "3     159         1        0         1        0         0        1        1   \n",
              "4      72         1        0         0        1         0        1        1   \n",
              "5    1828         0        1         1        0         0        1        1   \n",
              "..    ...       ...      ...       ...      ...       ...      ...      ...   \n",
              "457   209         1        0         1        0         0        1        1   \n",
              "458   115         1        0         0        1         0        1        1   \n",
              "459   143         1        0         1        0         0        1        1   \n",
              "460   150         1        0         0        1         0        1        0   \n",
              "461  2437         1        0         0        1         0        1        1   \n",
              "\n",
              "     APC_WT  TTN_SNV  TTN_WT  \n",
              "0         0        0       1  \n",
              "1         1        0       1  \n",
              "3         0        1       0  \n",
              "4         0        0       1  \n",
              "5         0        1       0  \n",
              "..      ...      ...     ...  \n",
              "457       0        1       0  \n",
              "458       0        0       1  \n",
              "459       0        0       1  \n",
              "460       1        0       1  \n",
              "461       0        1       0  \n",
              "\n",
              "[435 rows x 16 columns]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_df_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "rKR2DH0n_Jxj",
        "outputId": "73d5abc8-f4bf-4aab-f644-2c41fc91986e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gene Name</th>\n",
              "      <th>TCGA-CK-5912-01A</th>\n",
              "      <th>TCGA-QG-A5Z2-01A</th>\n",
              "      <th>TCGA-AG-3898-01A</th>\n",
              "      <th>TCGA-G4-6299-01A</th>\n",
              "      <th>TCGA-AG-4008-01A</th>\n",
              "      <th>TCGA-NH-A8F8-01A</th>\n",
              "      <th>TCGA-AD-6548-01A</th>\n",
              "      <th>TCGA-AA-A02Y-01A</th>\n",
              "      <th>TCGA-EI-6514-01A</th>\n",
              "      <th>...</th>\n",
              "      <th>TCGA-CL-5918-01A</th>\n",
              "      <th>TCGA-AG-A01Y-01A</th>\n",
              "      <th>TCGA-AG-A014-01A</th>\n",
              "      <th>TCGA-AG-A016-01A</th>\n",
              "      <th>TCGA-AA-3846-01A</th>\n",
              "      <th>TCGA-CA-5797-01A</th>\n",
              "      <th>TCGA-AA-3860-01A</th>\n",
              "      <th>TCGA-CK-4951-01A</th>\n",
              "      <th>TCGA-EI-6507-01A</th>\n",
              "      <th>TCGA-AA-3858-01A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ND4</td>\n",
              "      <td>7439.062895</td>\n",
              "      <td>8792.765169</td>\n",
              "      <td>17741.598452</td>\n",
              "      <td>6450.806633</td>\n",
              "      <td>10379.725197</td>\n",
              "      <td>13618.803856</td>\n",
              "      <td>4883.319842</td>\n",
              "      <td>10904.053119</td>\n",
              "      <td>34408.636657</td>\n",
              "      <td>...</td>\n",
              "      <td>22366.585071</td>\n",
              "      <td>10081.295778</td>\n",
              "      <td>19156.392713</td>\n",
              "      <td>10920.245725</td>\n",
              "      <td>18030.805728</td>\n",
              "      <td>4613.034188</td>\n",
              "      <td>8050.727061</td>\n",
              "      <td>13644.701244</td>\n",
              "      <td>3828.225667</td>\n",
              "      <td>5582.080285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COX1</td>\n",
              "      <td>4588.595848</td>\n",
              "      <td>9179.570665</td>\n",
              "      <td>11187.679200</td>\n",
              "      <td>1745.571204</td>\n",
              "      <td>6877.826691</td>\n",
              "      <td>14607.767247</td>\n",
              "      <td>6320.301079</td>\n",
              "      <td>17692.780153</td>\n",
              "      <td>16983.858426</td>\n",
              "      <td>...</td>\n",
              "      <td>11651.610855</td>\n",
              "      <td>7072.139210</td>\n",
              "      <td>14872.076963</td>\n",
              "      <td>9611.080727</td>\n",
              "      <td>15650.744139</td>\n",
              "      <td>5164.416460</td>\n",
              "      <td>7346.507790</td>\n",
              "      <td>9686.963776</td>\n",
              "      <td>3810.970106</td>\n",
              "      <td>5264.088803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COX2</td>\n",
              "      <td>5665.103979</td>\n",
              "      <td>7596.512070</td>\n",
              "      <td>11055.951503</td>\n",
              "      <td>5026.812800</td>\n",
              "      <td>6617.808230</td>\n",
              "      <td>13740.376202</td>\n",
              "      <td>4524.603112</td>\n",
              "      <td>13061.462981</td>\n",
              "      <td>14814.158978</td>\n",
              "      <td>...</td>\n",
              "      <td>15911.884141</td>\n",
              "      <td>3991.009966</td>\n",
              "      <td>12529.050771</td>\n",
              "      <td>8389.117994</td>\n",
              "      <td>9367.293818</td>\n",
              "      <td>4849.526536</td>\n",
              "      <td>4973.265758</td>\n",
              "      <td>7795.811346</td>\n",
              "      <td>2130.449835</td>\n",
              "      <td>4605.904253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COX3</td>\n",
              "      <td>5680.598793</td>\n",
              "      <td>3747.133467</td>\n",
              "      <td>9781.071390</td>\n",
              "      <td>5598.064967</td>\n",
              "      <td>8928.610414</td>\n",
              "      <td>16317.781297</td>\n",
              "      <td>4059.283216</td>\n",
              "      <td>8886.363990</td>\n",
              "      <td>9798.354702</td>\n",
              "      <td>...</td>\n",
              "      <td>15178.249808</td>\n",
              "      <td>4761.629711</td>\n",
              "      <td>7174.955206</td>\n",
              "      <td>4328.614100</td>\n",
              "      <td>11792.030134</td>\n",
              "      <td>5076.902442</td>\n",
              "      <td>6023.730019</td>\n",
              "      <td>7962.682400</td>\n",
              "      <td>1851.097403</td>\n",
              "      <td>6373.705624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACTB</td>\n",
              "      <td>3011.702557</td>\n",
              "      <td>4554.515176</td>\n",
              "      <td>5636.110428</td>\n",
              "      <td>5982.935436</td>\n",
              "      <td>5166.857187</td>\n",
              "      <td>5089.118824</td>\n",
              "      <td>9597.852910</td>\n",
              "      <td>6126.678103</td>\n",
              "      <td>5305.813227</td>\n",
              "      <td>...</td>\n",
              "      <td>6118.098222</td>\n",
              "      <td>4899.143970</td>\n",
              "      <td>8065.590162</td>\n",
              "      <td>9689.291319</td>\n",
              "      <td>4310.038411</td>\n",
              "      <td>7102.109461</td>\n",
              "      <td>5735.531169</td>\n",
              "      <td>8355.840116</td>\n",
              "      <td>4795.597686</td>\n",
              "      <td>6972.917209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33374</th>\n",
              "      <td>PRAMEF13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33375</th>\n",
              "      <td>OR8B4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33376</th>\n",
              "      <td>OR1S1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33377</th>\n",
              "      <td>PRAMEF26</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33378</th>\n",
              "      <td>DUX4L25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33377 rows × 463 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Gene Name  TCGA-CK-5912-01A  TCGA-QG-A5Z2-01A  TCGA-AG-3898-01A  \\\n",
              "0           ND4       7439.062895       8792.765169      17741.598452   \n",
              "1          COX1       4588.595848       9179.570665      11187.679200   \n",
              "2          COX2       5665.103979       7596.512070      11055.951503   \n",
              "3          COX3       5680.598793       3747.133467       9781.071390   \n",
              "4          ACTB       3011.702557       4554.515176       5636.110428   \n",
              "...         ...               ...               ...               ...   \n",
              "33374  PRAMEF13          0.000000          0.000000          0.000000   \n",
              "33375     OR8B4          0.000000          0.000000          0.000000   \n",
              "33376     OR1S1          0.000000          0.000000          0.000000   \n",
              "33377  PRAMEF26          0.000000          0.000000          0.000000   \n",
              "33378   DUX4L25          0.000000          0.000000          0.000000   \n",
              "\n",
              "       TCGA-G4-6299-01A  TCGA-AG-4008-01A  TCGA-NH-A8F8-01A  TCGA-AD-6548-01A  \\\n",
              "0           6450.806633      10379.725197      13618.803856       4883.319842   \n",
              "1           1745.571204       6877.826691      14607.767247       6320.301079   \n",
              "2           5026.812800       6617.808230      13740.376202       4524.603112   \n",
              "3           5598.064967       8928.610414      16317.781297       4059.283216   \n",
              "4           5982.935436       5166.857187       5089.118824       9597.852910   \n",
              "...                 ...               ...               ...               ...   \n",
              "33374          0.000000          0.000000          0.000000          0.000000   \n",
              "33375          0.000000          0.000000          0.000000          0.000000   \n",
              "33376          0.000000          0.000000          0.000000          0.000000   \n",
              "33377          0.000000          0.000000          0.000000          0.000000   \n",
              "33378          0.000000          0.000000          0.000000          0.000000   \n",
              "\n",
              "       TCGA-AA-A02Y-01A  TCGA-EI-6514-01A  ...  TCGA-CL-5918-01A  \\\n",
              "0          10904.053119      34408.636657  ...      22366.585071   \n",
              "1          17692.780153      16983.858426  ...      11651.610855   \n",
              "2          13061.462981      14814.158978  ...      15911.884141   \n",
              "3           8886.363990       9798.354702  ...      15178.249808   \n",
              "4           6126.678103       5305.813227  ...       6118.098222   \n",
              "...                 ...               ...  ...               ...   \n",
              "33374          0.000000          0.000000  ...          0.000000   \n",
              "33375          0.000000          0.000000  ...          0.000000   \n",
              "33376          0.000000          0.000000  ...          0.000000   \n",
              "33377          0.000000          0.000000  ...          0.000000   \n",
              "33378          0.000000          0.000000  ...          0.000000   \n",
              "\n",
              "       TCGA-AG-A01Y-01A  TCGA-AG-A014-01A  TCGA-AG-A016-01A  TCGA-AA-3846-01A  \\\n",
              "0          10081.295778      19156.392713      10920.245725      18030.805728   \n",
              "1           7072.139210      14872.076963       9611.080727      15650.744139   \n",
              "2           3991.009966      12529.050771       8389.117994       9367.293818   \n",
              "3           4761.629711       7174.955206       4328.614100      11792.030134   \n",
              "4           4899.143970       8065.590162       9689.291319       4310.038411   \n",
              "...                 ...               ...               ...               ...   \n",
              "33374          0.000000          0.000000          0.000000          0.000000   \n",
              "33375          0.000000          0.000000          0.000000          0.000000   \n",
              "33376          0.000000          0.000000          0.000000          0.000000   \n",
              "33377          0.000000          0.000000          0.000000          0.000000   \n",
              "33378          0.000000          0.000000          0.000000          0.000000   \n",
              "\n",
              "       TCGA-CA-5797-01A  TCGA-AA-3860-01A  TCGA-CK-4951-01A  TCGA-EI-6507-01A  \\\n",
              "0           4613.034188       8050.727061      13644.701244       3828.225667   \n",
              "1           5164.416460       7346.507790       9686.963776       3810.970106   \n",
              "2           4849.526536       4973.265758       7795.811346       2130.449835   \n",
              "3           5076.902442       6023.730019       7962.682400       1851.097403   \n",
              "4           7102.109461       5735.531169       8355.840116       4795.597686   \n",
              "...                 ...               ...               ...               ...   \n",
              "33374          0.000000          0.000000          0.000000          0.000000   \n",
              "33375          0.000000          0.000000          0.000000          0.000000   \n",
              "33376          0.000000          0.000000          0.000000          0.000000   \n",
              "33377          0.000000          0.000000          0.000000          0.000000   \n",
              "33378          0.000000          0.000000          0.000000          0.000000   \n",
              "\n",
              "       TCGA-AA-3858-01A  \n",
              "0           5582.080285  \n",
              "1           5264.088803  \n",
              "2           4605.904253  \n",
              "3           6373.705624  \n",
              "4           6972.917209  \n",
              "...                 ...  \n",
              "33374          0.000000  \n",
              "33375          0.000000  \n",
              "33376          0.000000  \n",
              "33377          0.000000  \n",
              "33378          0.000000  \n",
              "\n",
              "[33377 rows x 463 columns]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cpm_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OzCdNVqMR27",
        "outputId": "2596e985-1d17-4981-cc88-59f029669dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(33377, 463)\n",
            "(435, 16)\n"
          ]
        }
      ],
      "source": [
        "print(cpm_df.shape)\n",
        "print(pred_df_num.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJg0mCRfOKCB"
      },
      "source": [
        "Transpose counts df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Q0goSqzgOQLO"
      },
      "outputs": [],
      "source": [
        "cpm_df = cpm_df.transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvmeGs-6MSac"
      },
      "source": [
        "# Now remove the samples from the count_df that we dont have msi values for"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icB5NyBBN2Tm"
      },
      "source": [
        "Add sample names back to pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "tjy_grXsMeyw"
      },
      "outputs": [],
      "source": [
        "# Load the mapping dictionary from the file\n",
        "import json\n",
        "with open('id_to_num.json', 'r') as f:\n",
        "    num_to_id = json.load(f)\n",
        "\n",
        "# Reverse the mapping dictionary\n",
        "num_to_id = {v: k for k, v in num_to_id.items()}\n",
        "\n",
        "# Map the numbers back to the gene names\n",
        "pred_df_num['Unnamed: 0'] = pred_df_num['Unnamed: 0'].map(num_to_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifKnH9miOeOE"
      },
      "source": [
        "Remove the samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "gy9bUt8_XvQh"
      },
      "outputs": [],
      "source": [
        "# Set the first row as column names\n",
        "cpm_df = cpm_df.set_axis(cpm_df.iloc[0], axis=1)\n",
        "\n",
        "# Dropa the first row after setting column names\n",
        "cpm_df = cpm_df[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "CvkMzpTbYyuo"
      },
      "outputs": [],
      "source": [
        "pred_df_num = pred_df_num.set_index('Unnamed: 0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCK7vqXGOdgB",
        "outputId": "cfe1a740-5c4b-4f79-cd19-5bfb88876c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of common samples: 435\n",
            "Samples in cpm_df but not in pred_df_num: {'TCGA-D5-6540-01A', 'TCGA-AA-3956-01A', 'TCGA-AA-A02O-01A', 'TCGA-CA-6718-01A', 'TCGA-A6-3810-01A', 'TCGA-F5-6814-01A', 'TCGA-AG-A032-01A', 'TCGA-A6-2684-01A', 'TCGA-AA-A03F-01A', 'TCGA-A6-5659-01A', 'TCGA-AA-A02Y-01A', 'TCGA-AA-A01R-01A', 'TCGA-4T-AA8H-01A', 'TCGA-AA-A01S-01A', 'TCGA-A6-3809-01A', 'TCGA-A6-6780-01A', 'TCGA-AA-3666-01A', 'TCGA-AA-A01T-01A', 'TCGA-A6-2677-01A', 'TCGA-AG-3885-01A', 'TCGA-A6-2680-01A', 'TCGA-AG-3896-01A', 'TCGA-A6-6650-01A', 'TCGA-A6-5656-01A', 'TCGA-NH-A8F7-01A', 'TCGA-A6-2681-01A', 'TCGA-AG-4015-01A'}\n",
            "Samples in pred_df_num but not in cpm_df: set()\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\manos\\AppData\\Local\\Temp\\ipykernel_17532\\3429427196.py:9: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
            "  cpm_df_common = cpm_df.loc[common_samples]\n",
            "C:\\Users\\manos\\AppData\\Local\\Temp\\ipykernel_17532\\3429427196.py:12: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
            "  pred_df_common = pred_df_num.loc[common_samples]\n"
          ]
        }
      ],
      "source": [
        "# Get the common sample names between the two dataframes\n",
        "common_samples = set(cpm_df.index).intersection(set(pred_df_num.index))\n",
        "\n",
        "print(\"Number of common samples:\", len(common_samples))\n",
        "print(\"Samples in cpm_df but not in pred_df_num:\", set(cpm_df.index) - common_samples)\n",
        "print(\"Samples in pred_df_num but not in cpm_df:\", set(pred_df_num.index) - common_samples)\n",
        "\n",
        "# Reduce cpm_df to only the common samples\n",
        "cpm_df_common = cpm_df.loc[common_samples]\n",
        "\n",
        "# Reduce pred_df_num to only the common samples\n",
        "pred_df_common = pred_df_num.loc[common_samples]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XwF90p6fXcO0",
        "outputId": "c6a0db88-ad8e-41da-f064-c9a67590f72b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Gene Name</th>\n",
              "      <th>ND4</th>\n",
              "      <th>COX1</th>\n",
              "      <th>COX2</th>\n",
              "      <th>COX3</th>\n",
              "      <th>ACTB</th>\n",
              "      <th>EEF1A1</th>\n",
              "      <th>CYTB</th>\n",
              "      <th>ACTG1</th>\n",
              "      <th>ND2</th>\n",
              "      <th>ATP6</th>\n",
              "      <th>...</th>\n",
              "      <th>MIR8060</th>\n",
              "      <th>RNU6-156P</th>\n",
              "      <th>MIR6082</th>\n",
              "      <th>RN7SL82P</th>\n",
              "      <th>TP53TG3F</th>\n",
              "      <th>PRAMEF13</th>\n",
              "      <th>OR8B4</th>\n",
              "      <th>OR1S1</th>\n",
              "      <th>PRAMEF26</th>\n",
              "      <th>DUX4L25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TCGA-CM-6162-01A</th>\n",
              "      <td>3018.5236</td>\n",
              "      <td>3142.484368</td>\n",
              "      <td>2163.196349</td>\n",
              "      <td>1983.679681</td>\n",
              "      <td>7670.607898</td>\n",
              "      <td>4605.565709</td>\n",
              "      <td>1313.730031</td>\n",
              "      <td>4406.048097</td>\n",
              "      <td>889.42722</td>\n",
              "      <td>1561.999944</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AM-5820-01A</th>\n",
              "      <td>7721.87757</td>\n",
              "      <td>6964.507384</td>\n",
              "      <td>5923.792379</td>\n",
              "      <td>5470.57343</td>\n",
              "      <td>6792.47586</td>\n",
              "      <td>3686.07568</td>\n",
              "      <td>2687.118718</td>\n",
              "      <td>3816.452881</td>\n",
              "      <td>4900.626954</td>\n",
              "      <td>4128.839559</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-DM-A28F-01A</th>\n",
              "      <td>5758.284953</td>\n",
              "      <td>9567.860735</td>\n",
              "      <td>10060.701823</td>\n",
              "      <td>7465.82396</td>\n",
              "      <td>9394.093861</td>\n",
              "      <td>3566.702344</td>\n",
              "      <td>4935.190893</td>\n",
              "      <td>3851.264618</td>\n",
              "      <td>2694.494502</td>\n",
              "      <td>3055.654431</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AA-3713-01A</th>\n",
              "      <td>8364.108127</td>\n",
              "      <td>11747.942995</td>\n",
              "      <td>4958.916605</td>\n",
              "      <td>4278.595247</td>\n",
              "      <td>4660.966615</td>\n",
              "      <td>4382.514529</td>\n",
              "      <td>3986.847411</td>\n",
              "      <td>4702.541914</td>\n",
              "      <td>3621.678962</td>\n",
              "      <td>3400.848117</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-CI-6619-01B</th>\n",
              "      <td>11883.738446</td>\n",
              "      <td>17031.496164</td>\n",
              "      <td>8934.483845</td>\n",
              "      <td>9356.118867</td>\n",
              "      <td>4533.280588</td>\n",
              "      <td>6531.32069</td>\n",
              "      <td>5440.536806</td>\n",
              "      <td>4104.171923</td>\n",
              "      <td>5508.296619</td>\n",
              "      <td>5095.423801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AG-A015-01A</th>\n",
              "      <td>16473.757103</td>\n",
              "      <td>12542.062865</td>\n",
              "      <td>12249.294299</td>\n",
              "      <td>10459.058217</td>\n",
              "      <td>6122.810039</td>\n",
              "      <td>7124.814494</td>\n",
              "      <td>10578.971412</td>\n",
              "      <td>3792.29654</td>\n",
              "      <td>4119.803191</td>\n",
              "      <td>6913.825167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AA-3869-01A</th>\n",
              "      <td>8380.11131</td>\n",
              "      <td>12700.280833</td>\n",
              "      <td>7297.584226</td>\n",
              "      <td>6787.067565</td>\n",
              "      <td>5715.874958</td>\n",
              "      <td>6561.942871</td>\n",
              "      <td>5361.249641</td>\n",
              "      <td>2778.807608</td>\n",
              "      <td>2288.168574</td>\n",
              "      <td>4252.881643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AD-6965-01A</th>\n",
              "      <td>1386.221378</td>\n",
              "      <td>2179.962035</td>\n",
              "      <td>1361.368647</td>\n",
              "      <td>1515.754443</td>\n",
              "      <td>5515.366341</td>\n",
              "      <td>5057.058908</td>\n",
              "      <td>592.769098</td>\n",
              "      <td>4834.590262</td>\n",
              "      <td>525.079486</td>\n",
              "      <td>479.463714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-CM-5864-01A</th>\n",
              "      <td>6140.774681</td>\n",
              "      <td>1947.339133</td>\n",
              "      <td>9136.2346</td>\n",
              "      <td>5231.169176</td>\n",
              "      <td>3960.275103</td>\n",
              "      <td>9484.516899</td>\n",
              "      <td>3200.464916</td>\n",
              "      <td>2934.982254</td>\n",
              "      <td>2743.429966</td>\n",
              "      <td>4097.599879</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-CM-6163-01A</th>\n",
              "      <td>11299.048512</td>\n",
              "      <td>11174.903712</td>\n",
              "      <td>9725.694616</td>\n",
              "      <td>7407.24273</td>\n",
              "      <td>5294.66112</td>\n",
              "      <td>4603.28918</td>\n",
              "      <td>7255.232197</td>\n",
              "      <td>4130.813171</td>\n",
              "      <td>5942.525083</td>\n",
              "      <td>6196.429848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>435 rows × 33377 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Gene Name                  ND4          COX1          COX2          COX3  \\\n",
              "TCGA-CM-6162-01A     3018.5236   3142.484368   2163.196349   1983.679681   \n",
              "TCGA-AM-5820-01A    7721.87757   6964.507384   5923.792379    5470.57343   \n",
              "TCGA-DM-A28F-01A   5758.284953   9567.860735  10060.701823    7465.82396   \n",
              "TCGA-AA-3713-01A   8364.108127  11747.942995   4958.916605   4278.595247   \n",
              "TCGA-CI-6619-01B  11883.738446  17031.496164   8934.483845   9356.118867   \n",
              "...                        ...           ...           ...           ...   \n",
              "TCGA-AG-A015-01A  16473.757103  12542.062865  12249.294299  10459.058217   \n",
              "TCGA-AA-3869-01A    8380.11131  12700.280833   7297.584226   6787.067565   \n",
              "TCGA-AD-6965-01A   1386.221378   2179.962035   1361.368647   1515.754443   \n",
              "TCGA-CM-5864-01A   6140.774681   1947.339133     9136.2346   5231.169176   \n",
              "TCGA-CM-6163-01A  11299.048512  11174.903712   9725.694616    7407.24273   \n",
              "\n",
              "Gene Name                ACTB       EEF1A1          CYTB        ACTG1  \\\n",
              "TCGA-CM-6162-01A  7670.607898  4605.565709   1313.730031  4406.048097   \n",
              "TCGA-AM-5820-01A   6792.47586   3686.07568   2687.118718  3816.452881   \n",
              "TCGA-DM-A28F-01A  9394.093861  3566.702344   4935.190893  3851.264618   \n",
              "TCGA-AA-3713-01A  4660.966615  4382.514529   3986.847411  4702.541914   \n",
              "TCGA-CI-6619-01B  4533.280588   6531.32069   5440.536806  4104.171923   \n",
              "...                       ...          ...           ...          ...   \n",
              "TCGA-AG-A015-01A  6122.810039  7124.814494  10578.971412   3792.29654   \n",
              "TCGA-AA-3869-01A  5715.874958  6561.942871   5361.249641  2778.807608   \n",
              "TCGA-AD-6965-01A  5515.366341  5057.058908    592.769098  4834.590262   \n",
              "TCGA-CM-5864-01A  3960.275103  9484.516899   3200.464916  2934.982254   \n",
              "TCGA-CM-6163-01A   5294.66112   4603.28918   7255.232197  4130.813171   \n",
              "\n",
              "Gene Name                 ND2         ATP6  ... MIR8060 RNU6-156P MIR6082  \\\n",
              "TCGA-CM-6162-01A    889.42722  1561.999944  ...     0.0       0.0     0.0   \n",
              "TCGA-AM-5820-01A  4900.626954  4128.839559  ...     0.0       0.0     0.0   \n",
              "TCGA-DM-A28F-01A  2694.494502  3055.654431  ...     0.0       0.0     0.0   \n",
              "TCGA-AA-3713-01A  3621.678962  3400.848117  ...     0.0       0.0     0.0   \n",
              "TCGA-CI-6619-01B  5508.296619  5095.423801  ...     0.0       0.0     0.0   \n",
              "...                       ...          ...  ...     ...       ...     ...   \n",
              "TCGA-AG-A015-01A  4119.803191  6913.825167  ...     0.0       0.0     0.0   \n",
              "TCGA-AA-3869-01A  2288.168574  4252.881643  ...     0.0       0.0     0.0   \n",
              "TCGA-AD-6965-01A   525.079486   479.463714  ...     0.0       0.0     0.0   \n",
              "TCGA-CM-5864-01A  2743.429966  4097.599879  ...     0.0       0.0     0.0   \n",
              "TCGA-CM-6163-01A  5942.525083  6196.429848  ...     0.0       0.0     0.0   \n",
              "\n",
              "Gene Name        RN7SL82P TP53TG3F PRAMEF13 OR8B4 OR1S1 PRAMEF26 DUX4L25  \n",
              "TCGA-CM-6162-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-AM-5820-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-DM-A28F-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-AA-3713-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-CI-6619-01B      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "...                   ...      ...      ...   ...   ...      ...     ...  \n",
              "TCGA-AG-A015-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-AA-3869-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-AD-6965-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-CM-5864-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "TCGA-CM-6163-01A      0.0      0.0      0.0   0.0   0.0      0.0     0.0  \n",
              "\n",
              "[435 rows x 33377 columns]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cpm_df_common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDmPh5GU7tXa"
      },
      "source": [
        "Splittng the data into Train, Test, Validation Sets | changed the train_size=0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "vHvhKMAq7tXa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "pred_df_common['msi_status']=pred_df_common['msi_status'].astype(int)\n",
        "X = cpm_df_common.iloc[:,1:]\n",
        "y = pred_df_common['msi_status']\n",
        "\n",
        "##  selected random state 42 so that now you get the same result each time you run the function\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.6, random_state=42)\n",
        "\n",
        "## validation data is the same size as your test set, but you can make it a littler smaller to get some more training data\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW4att6F7tXb",
        "outputId": "f1be94e5-18ca-4b16-ed05-ad7d0da4fe6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xtrain (261, 33376)\n",
            "ytrain (261,)\n",
            "Xtest (87, 33376)\n",
            "Xvalid (87, 33376)\n"
          ]
        }
      ],
      "source": [
        "print('Xtrain',X_train.shape)\n",
        "print('ytrain',y_train.shape)\n",
        "print('Xtest',X_valid.shape)\n",
        "print('Xvalid',X_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "_Rg0p_2o7tXb"
      },
      "outputs": [],
      "source": [
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from matplotlib import pyplot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MNE9Rhq7tXb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFpNLRLN7tXb",
        "outputId": "bd93842b-b0db-4f0f-9cc1-9f43252e8058"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Gene Name\n",
              "TRIM7      0.688409\n",
              "MLH1       0.634188\n",
              "AGR2       0.628659\n",
              "HPSE       0.611010\n",
              "RPL22L1    0.609128\n",
              "             ...   \n",
              "CLCN7      0.300379\n",
              "NECAP1     0.300247\n",
              "AP5Z1      0.300127\n",
              "ABAT       0.300088\n",
              "SYS1       0.300020\n",
              "Length: 1147, dtype: float64"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_val=X_train.astype(int)\n",
        "y_train_val=y_train.astype(int)\n",
        "# Calculate the correlation matrix between the X input features and y output feature\n",
        "corr_matrix = X_train_val.corrwith(y_train_val)\n",
        "#drop nan values\n",
        "corr_matrix_nan=corr_matrix.dropna()\n",
        "#convert to absolute\n",
        "corr_matrix_abs=corr_matrix_nan.abs()\n",
        "#sort values\n",
        "coor_matrix_sorted=corr_matrix_abs.sort_values(ascending=False)\n",
        "#set threshold\n",
        "threshold = 0.3\n",
        "#select features\n",
        "Selected_features=coor_matrix_sorted[coor_matrix_sorted>=threshold]\n",
        "Selected_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "N5ITO5IC7tXb"
      },
      "outputs": [],
      "source": [
        "#keep only the selected features in Xtrain, xtest,xvalid\n",
        "X_train  =X_train.loc[:, X_train.columns.isin(Selected_features.index)]\n",
        "X_test = X_test.loc[:, X_test.columns.isin(Selected_features.index)]\n",
        "X_valid = X_valid.loc[:, X_valid.columns.isin(Selected_features.index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "JM8OroUh6fok"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/500 selected features: KCNK1\n",
            "2/500 selected features: CTDP1\n",
            "3/500 selected features: RHOU\n",
            "4/500 selected features: SOCS6\n",
            "5/500 selected features: MYLIP\n",
            "6/500 selected features: CRYZ\n",
            "7/500 selected features: STIM2\n",
            "8/500 selected features: PGAP4\n",
            "9/500 selected features: MRE11\n",
            "10/500 selected features: MFAP1\n",
            "11/500 selected features: ABHD10\n",
            "12/500 selected features: TRIM69\n",
            "13/500 selected features: ABAT\n",
            "14/500 selected features: NMI\n",
            "15/500 selected features: NAA38\n",
            "16/500 selected features: TRMT2B\n",
            "17/500 selected features: INPP1\n",
            "18/500 selected features: MAFF\n",
            "19/500 selected features: TTPAL\n",
            "20/500 selected features: TDGF1\n",
            "21/500 selected features: LARP1B\n",
            "22/500 selected features: USPL1\n",
            "23/500 selected features: ZBTB10\n",
            "24/500 selected features: ADNP2\n",
            "25/500 selected features: JKAMP\n",
            "26/500 selected features: LTN1\n",
            "27/500 selected features: SHROOM4\n",
            "28/500 selected features: RBBP8\n",
            "29/500 selected features: ZNRF2\n",
            "30/500 selected features: GGT7\n",
            "31/500 selected features: HCG18\n",
            "32/500 selected features: TENT5A\n",
            "33/500 selected features: NGEF\n",
            "34/500 selected features: CADPS2\n",
            "35/500 selected features: ENO2\n",
            "36/500 selected features: PXMP4\n",
            "37/500 selected features: PLAGL1\n",
            "38/500 selected features: SLC7A11\n",
            "39/500 selected features: LINC01184\n",
            "40/500 selected features: ARNTL2\n",
            "41/500 selected features: CXorf56\n",
            "42/500 selected features: UBE2F\n",
            "43/500 selected features: CXCL10\n",
            "44/500 selected features: CLCN5\n",
            "45/500 selected features: ZNF503\n",
            "46/500 selected features: PLK2\n",
            "47/500 selected features: OXCT1\n",
            "48/500 selected features: FGD4\n",
            "49/500 selected features: EFNA4\n",
            "50/500 selected features: AOAH\n",
            "51/500 selected features: LEO1\n",
            "52/500 selected features: RIN1\n",
            "53/500 selected features: DERL2\n",
            "54/500 selected features: SRD5A3\n",
            "55/500 selected features: HLA-DMB\n",
            "56/500 selected features: RNF138\n",
            "57/500 selected features: MLH1\n",
            "58/500 selected features: SS18L1\n",
            "59/500 selected features: CAB39L\n",
            "60/500 selected features: NT5DC3\n",
            "61/500 selected features: RARRES1\n",
            "62/500 selected features: CEP164\n",
            "63/500 selected features: ADGRG6\n",
            "64/500 selected features: ELP5\n",
            "65/500 selected features: DAPK2\n",
            "66/500 selected features: NIPA1\n",
            "67/500 selected features: MTHFR\n",
            "68/500 selected features: DTL\n",
            "69/500 selected features: NKD2\n",
            "70/500 selected features: CITED2\n",
            "71/500 selected features: A1CF\n",
            "72/500 selected features: NCAPG\n",
            "73/500 selected features: SNHG18\n",
            "74/500 selected features: KLF7\n",
            "75/500 selected features: SLC7A6\n",
            "76/500 selected features: GCH1\n",
            "77/500 selected features: JADE3\n",
            "78/500 selected features: RFC5\n",
            "79/500 selected features: PAAF1\n",
            "80/500 selected features: SPDEF\n",
            "81/500 selected features: C2CD4A\n",
            "82/500 selected features: TRIB2\n",
            "83/500 selected features: MAP2K4\n",
            "84/500 selected features: KCTD9\n",
            "85/500 selected features: WDR41\n",
            "86/500 selected features: EXOSC9\n",
            "87/500 selected features: PBK\n",
            "88/500 selected features: STRN3\n",
            "89/500 selected features: SECTM1\n",
            "90/500 selected features: DDB2\n",
            "91/500 selected features: SLC25A26\n",
            "92/500 selected features: SLC22A3\n",
            "93/500 selected features: PHLPP1\n",
            "94/500 selected features: TOP3A\n",
            "95/500 selected features: SGK2\n",
            "96/500 selected features: MOCS3\n",
            "97/500 selected features: KDM7A-DT\n",
            "98/500 selected features: PKNOX1\n",
            "99/500 selected features: CIITA\n",
            "100/500 selected features: ZFYVE19\n",
            "101/500 selected features: STS\n",
            "102/500 selected features: FAM217B\n",
            "103/500 selected features: MAP3K6\n",
            "104/500 selected features: TMEM64\n",
            "105/500 selected features: DHX35\n",
            "106/500 selected features: ELOVL7\n",
            "107/500 selected features: SERPINB9\n",
            "108/500 selected features: DCPS\n",
            "109/500 selected features: MOGAT3\n",
            "110/500 selected features: MUC6\n",
            "111/500 selected features: PRPSAP2\n",
            "112/500 selected features: CHFR\n",
            "113/500 selected features: IDO1\n",
            "114/500 selected features: TNFRSF10A\n",
            "115/500 selected features: AFAP1L2\n",
            "116/500 selected features: CDC45\n",
            "117/500 selected features: MANEAL\n",
            "118/500 selected features: C1orf226\n",
            "119/500 selected features: ZSWIM1\n",
            "120/500 selected features: TRIM16\n",
            "121/500 selected features: ARHGEF9\n",
            "122/500 selected features: DAPK1\n",
            "123/500 selected features: PPP1R14C\n",
            "124/500 selected features: CDC42EP2\n",
            "125/500 selected features: ENOX2\n",
            "126/500 selected features: C18orf25\n",
            "127/500 selected features: TMEM243\n",
            "128/500 selected features: VANGL2\n",
            "129/500 selected features: FBXL12\n",
            "130/500 selected features: SLC35E4\n",
            "131/500 selected features: IL1RN\n",
            "132/500 selected features: GCAT\n",
            "133/500 selected features: SGMS1\n",
            "134/500 selected features: TBC1D8\n",
            "135/500 selected features: ZNF783\n",
            "136/500 selected features: ISG20\n",
            "137/500 selected features: EPM2AIP1\n",
            "138/500 selected features: LRRC19\n",
            "139/500 selected features: PSMD9\n",
            "140/500 selected features: ZNF480\n",
            "141/500 selected features: CENPM\n",
            "142/500 selected features: APOL3\n",
            "143/500 selected features: LACTB\n",
            "144/500 selected features: NFATC2\n",
            "145/500 selected features: SAMD9L\n",
            "146/500 selected features: RNF113A\n",
            "147/500 selected features: EIF4E3\n",
            "148/500 selected features: CCL5\n",
            "149/500 selected features: CSNK1G1\n",
            "150/500 selected features: SHANK2\n",
            "151/500 selected features: NDUFA4L2\n",
            "152/500 selected features: RMC1\n",
            "153/500 selected features: JADE1\n",
            "154/500 selected features: ANG\n",
            "155/500 selected features: SLC18B1\n",
            "156/500 selected features: DYRK4\n",
            "157/500 selected features: MEX3A\n",
            "158/500 selected features: ERI1\n",
            "159/500 selected features: ZNF513\n",
            "160/500 selected features: TVP23B\n",
            "161/500 selected features: TPBG\n",
            "162/500 selected features: ZSCAN25\n",
            "163/500 selected features: ETV5\n",
            "164/500 selected features: GAS2L1\n",
            "165/500 selected features: TYW3\n",
            "166/500 selected features: HENMT1\n",
            "167/500 selected features: MT1X\n",
            "168/500 selected features: MOCOS\n",
            "169/500 selected features: ALDH1L1\n",
            "170/500 selected features: NEIL2\n",
            "171/500 selected features: FAM174B\n",
            "172/500 selected features: CD109\n",
            "173/500 selected features: NUBPL\n",
            "174/500 selected features: SLC1A1\n",
            "175/500 selected features: CHAF1B\n",
            "176/500 selected features: SRBD1\n",
            "177/500 selected features: FFAR4\n",
            "178/500 selected features: CTSV\n",
            "179/500 selected features: GMEB1\n",
            "180/500 selected features: TNK1\n",
            "181/500 selected features: NAALADL2\n",
            "182/500 selected features: NR4A2\n",
            "183/500 selected features: SFXN5\n",
            "184/500 selected features: PPP1R3D\n",
            "185/500 selected features: RAMP1\n",
            "186/500 selected features: MAPRE3\n",
            "187/500 selected features: RAD51\n",
            "188/500 selected features: ZNF274\n",
            "189/500 selected features: TEF\n",
            "190/500 selected features: SLC43A3\n",
            "191/500 selected features: SMAP1\n",
            "192/500 selected features: JAK2\n",
            "193/500 selected features: ZCCHC2\n",
            "194/500 selected features: NPEPL1\n",
            "195/500 selected features: TIMM22\n",
            "196/500 selected features: ASRGL1\n",
            "197/500 selected features: ALKBH2\n",
            "198/500 selected features: ZNF830\n",
            "199/500 selected features: NUFIP1\n",
            "200/500 selected features: PIAS2\n",
            "201/500 selected features: RBFA\n",
            "202/500 selected features: DIO3OS\n",
            "203/500 selected features: NDC80\n",
            "204/500 selected features: TNFAIP8\n",
            "205/500 selected features: HAPLN3\n",
            "206/500 selected features: KHDRBS3\n",
            "207/500 selected features: DEPDC1\n",
            "208/500 selected features: GRM8\n",
            "209/500 selected features: ILDR1\n",
            "210/500 selected features: SLC35A1\n",
            "211/500 selected features: AMER1\n",
            "212/500 selected features: TNFSF13\n",
            "213/500 selected features: ORC1\n",
            "214/500 selected features: TIMM21\n",
            "215/500 selected features: SDR16C5\n",
            "216/500 selected features: PUSL1\n",
            "217/500 selected features: MRM3\n",
            "218/500 selected features: GSPT2\n",
            "219/500 selected features: TNNC2\n",
            "220/500 selected features: THUMPD3-AS1\n",
            "221/500 selected features: SMIM31\n",
            "222/500 selected features: PFKFB4\n",
            "223/500 selected features: PLLP\n",
            "224/500 selected features: BCLAF3\n",
            "225/500 selected features: MCUB\n",
            "226/500 selected features: EXO1\n",
            "227/500 selected features: FAS\n",
            "228/500 selected features: GBP5\n",
            "229/500 selected features: SERPINB8\n",
            "230/500 selected features: GAREM1\n",
            "231/500 selected features: ITGAE\n",
            "232/500 selected features: RILPL2\n",
            "233/500 selected features: RIC8B\n",
            "234/500 selected features: PPM1L\n",
            "235/500 selected features: SHROOM2\n",
            "236/500 selected features: ZNF618\n",
            "237/500 selected features: KLHL2\n",
            "238/500 selected features: SIDT1\n",
            "239/500 selected features: HSPA4L\n",
            "240/500 selected features: ETV7\n",
            "241/500 selected features: WDR76\n",
            "242/500 selected features: AMT\n",
            "243/500 selected features: FBXO6\n",
            "244/500 selected features: PRSS12\n",
            "245/500 selected features: WRAP53\n",
            "246/500 selected features: MED9\n",
            "247/500 selected features: FECH\n",
            "248/500 selected features: INO80C\n",
            "249/500 selected features: ATPAF2\n",
            "250/500 selected features: HLA-DRB6\n",
            "251/500 selected features: AGAP2-AS1\n",
            "252/500 selected features: RPS6KA6\n",
            "253/500 selected features: LINC00467\n",
            "254/500 selected features: TTC30A\n",
            "255/500 selected features: GPAT3\n",
            "256/500 selected features: TTC30B\n",
            "257/500 selected features: CD8A\n",
            "258/500 selected features: AIF1L\n",
            "259/500 selected features: TINAG\n",
            "260/500 selected features: DAPP1\n",
            "261/500 selected features: TMEM107\n",
            "262/500 selected features: KIAA0895\n",
            "263/500 selected features: LINC01089\n",
            "264/500 selected features: NXPH4\n",
            "265/500 selected features: TRIM7\n",
            "266/500 selected features: RNF144B\n",
            "267/500 selected features: TFAP2A\n",
            "268/500 selected features: PTMAP5\n",
            "269/500 selected features: KLHL3\n",
            "270/500 selected features: UBASH3B\n",
            "271/500 selected features: CCL4\n",
            "272/500 selected features: RNLS\n",
            "273/500 selected features: GNLY\n",
            "274/500 selected features: PELI3\n",
            "275/500 selected features: GCHFR\n",
            "276/500 selected features: SPAG4\n",
            "277/500 selected features: WASF1\n",
            "278/500 selected features: RNF152\n",
            "279/500 selected features: PINK1-AS\n",
            "280/500 selected features: CXCL13\n",
            "281/500 selected features: LINC01003\n",
            "282/500 selected features: ZNF470\n",
            "283/500 selected features: BARX2\n",
            "284/500 selected features: PLCL2\n",
            "285/500 selected features: RAB3B\n",
            "286/500 selected features: RCOR2\n",
            "287/500 selected features: ZNF423\n",
            "288/500 selected features: ZNF141\n",
            "289/500 selected features: DENND6B\n",
            "290/500 selected features: POLR3G\n",
            "291/500 selected features: USP18\n",
            "292/500 selected features: LRRC2\n",
            "293/500 selected features: PTGER2\n",
            "294/500 selected features: CELP\n",
            "295/500 selected features: LINC00662\n",
            "296/500 selected features: ZNF606\n",
            "297/500 selected features: RND1\n",
            "298/500 selected features: DNAH2\n",
            "299/500 selected features: ERO1B\n",
            "300/500 selected features: MAPK12\n",
            "301/500 selected features: HASPIN\n",
            "302/500 selected features: LOC101928881\n",
            "303/500 selected features: GZMA\n",
            "304/500 selected features: INKA2\n",
            "305/500 selected features: ZBTB8A\n",
            "306/500 selected features: RSPH1\n",
            "307/500 selected features: AGAP2\n",
            "308/500 selected features: OSR2\n",
            "309/500 selected features: ST6GALNAC2\n",
            "310/500 selected features: USP27X\n",
            "311/500 selected features: LINC00869\n",
            "312/500 selected features: ZNF165\n",
            "313/500 selected features: N4BP3\n",
            "314/500 selected features: RHOF\n",
            "315/500 selected features: ELAC1\n",
            "316/500 selected features: C18orf32\n",
            "317/500 selected features: RNASEK\n",
            "318/500 selected features: DNAJC3-DT\n",
            "319/500 selected features: PYROXD2\n",
            "320/500 selected features: KIAA1549L\n",
            "321/500 selected features: RAC3\n",
            "322/500 selected features: NKG7\n",
            "323/500 selected features: SNPH\n",
            "324/500 selected features: TP73\n",
            "325/500 selected features: KCTD1\n",
            "326/500 selected features: PNMA2\n",
            "327/500 selected features: C7orf31\n",
            "328/500 selected features: TSGA10\n",
            "329/500 selected features: CCNP\n",
            "330/500 selected features: RMDN2\n",
            "331/500 selected features: LINC01315\n",
            "332/500 selected features: TSPY26P\n",
            "333/500 selected features: MED31\n",
            "334/500 selected features: BHLHB9\n",
            "335/500 selected features: ATP6V1FNB\n",
            "336/500 selected features: EIF5AL1\n",
            "337/500 selected features: TCP11L2\n",
            "338/500 selected features: RAB26\n",
            "339/500 selected features: TNNT1\n",
            "340/500 selected features: CD274\n",
            "341/500 selected features: NRGN\n",
            "342/500 selected features: IL15\n",
            "343/500 selected features: FAM167A\n",
            "344/500 selected features: LOC389641\n",
            "345/500 selected features: CHAC2\n",
            "346/500 selected features: BCYRN1\n",
            "347/500 selected features: PDE10A\n",
            "348/500 selected features: MAPK11\n",
            "349/500 selected features: COQ10A\n",
            "350/500 selected features: LOC100506302\n",
            "351/500 selected features: APLF\n",
            "352/500 selected features: NPFFR1\n",
            "353/500 selected features: C8orf58\n",
            "354/500 selected features: LYPD5\n",
            "355/500 selected features: LAG3\n",
            "356/500 selected features: TRIM16L\n",
            "357/500 selected features: GJB5\n",
            "358/500 selected features: CRIP1\n",
            "359/500 selected features: TUSC8\n",
            "360/500 selected features: ZNF433-AS1\n",
            "361/500 selected features: ZXDA\n",
            "362/500 selected features: GFI1\n",
            "363/500 selected features: MPP3\n",
            "364/500 selected features: CBR3\n",
            "365/500 selected features: SPIN3\n",
            "366/500 selected features: CCDC134\n",
            "367/500 selected features: LINC02747\n",
            "368/500 selected features: ZMYND15\n",
            "369/500 selected features: APOBEC3F\n",
            "370/500 selected features: FLJ20021\n",
            "371/500 selected features: EPOR\n",
            "372/500 selected features: LRRC36\n",
            "373/500 selected features: DNM3\n",
            "374/500 selected features: GAD1\n",
            "375/500 selected features: ZNF286A\n",
            "376/500 selected features: RASGRP1\n",
            "377/500 selected features: SPIN2B\n",
            "378/500 selected features: DSTNP2\n",
            "379/500 selected features: PRDM8\n",
            "380/500 selected features: APOBEC3D\n",
            "381/500 selected features: ZNF630\n",
            "382/500 selected features: KCNJ3\n",
            "383/500 selected features: FMO4\n",
            "384/500 selected features: OTX1\n",
            "385/500 selected features: TSPOAP1-AS1\n",
            "386/500 selected features: DZANK1\n",
            "387/500 selected features: DYRK3\n",
            "388/500 selected features: NUDT7\n",
            "389/500 selected features: ROBO3\n",
            "390/500 selected features: UST\n",
            "391/500 selected features: KLRD1\n",
            "392/500 selected features: ZIC5\n",
            "393/500 selected features: ZNF345\n",
            "394/500 selected features: LINC00888\n",
            "395/500 selected features: NPHP1\n",
            "396/500 selected features: ZFP28\n",
            "397/500 selected features: LINC02487\n",
            "398/500 selected features: XKR9\n",
            "399/500 selected features: RAB3A\n",
            "400/500 selected features: ZNF543\n",
            "401/500 selected features: SPRY3\n",
            "402/500 selected features: CTSW\n",
            "403/500 selected features: LOC648987\n",
            "404/500 selected features: VNN2\n",
            "405/500 selected features: LOXL1-AS1\n",
            "406/500 selected features: CEP85L\n",
            "407/500 selected features: ADD3-AS1\n",
            "408/500 selected features: RNASE4\n",
            "409/500 selected features: NUDT6\n",
            "410/500 selected features: ACRBP\n",
            "411/500 selected features: ERFE\n",
            "412/500 selected features: MCMDC2\n",
            "413/500 selected features: PAX9\n",
            "414/500 selected features: ETFBKMT\n",
            "415/500 selected features: VSTM5\n",
            "416/500 selected features: FOXD1\n",
            "417/500 selected features: INSM1\n",
            "418/500 selected features: FAM78B\n",
            "419/500 selected features: ULBP2\n",
            "420/500 selected features: WFDC21P\n",
            "421/500 selected features: TCAF2\n",
            "422/500 selected features: IGFALS\n",
            "423/500 selected features: PTPRD-AS1\n",
            "424/500 selected features: MTMR8\n",
            "425/500 selected features: HOXC6\n",
            "426/500 selected features: RPL13P5\n",
            "427/500 selected features: FBXO16\n",
            "428/500 selected features: KLHL31\n",
            "429/500 selected features: GZMH\n",
            "430/500 selected features: BATF3\n",
            "431/500 selected features: NRTN\n",
            "432/500 selected features: HSD17B1\n",
            "433/500 selected features: LINC02441\n",
            "434/500 selected features: GPR3\n",
            "435/500 selected features: LINC02688\n",
            "436/500 selected features: TRPV6\n",
            "437/500 selected features: ADNP-AS1\n",
            "438/500 selected features: HSPA1L\n",
            "439/500 selected features: LINC01504\n",
            "440/500 selected features: CHRM1\n",
            "441/500 selected features: CYB5D1\n",
            "442/500 selected features: SEMG1\n",
            "443/500 selected features: SPTB\n",
            "444/500 selected features: TSC22D1-AS1\n",
            "445/500 selected features: SPATA25\n",
            "446/500 selected features: TMEM61\n",
            "447/500 selected features: NKX3-1\n",
            "448/500 selected features: GBP1P1\n",
            "449/500 selected features: TLE6\n",
            "450/500 selected features: BEGAIN\n",
            "451/500 selected features: ANXA2R\n",
            "452/500 selected features: C16orf46\n",
            "453/500 selected features: B3GNT4\n",
            "454/500 selected features: ZNF683\n",
            "455/500 selected features: CD68\n",
            "456/500 selected features: MIR924HG\n",
            "457/500 selected features: LINC01547\n",
            "458/500 selected features: ISL1\n",
            "459/500 selected features: SNAI3\n",
            "460/500 selected features: LRRC73\n",
            "461/500 selected features: AKAP3\n",
            "462/500 selected features: DNAAF3\n",
            "463/500 selected features: ZMYND12\n",
            "464/500 selected features: CIRBP-AS1\n",
            "465/500 selected features: HOXC4\n",
            "466/500 selected features: NEURL2\n",
            "467/500 selected features: SYT12\n",
            "468/500 selected features: SLC25A48\n",
            "469/500 selected features: DARS1-AS1\n",
            "470/500 selected features: FAM72B\n",
            "471/500 selected features: COSMOC\n",
            "472/500 selected features: DLGAP1-AS5\n",
            "473/500 selected features: CHRNA7\n",
            "474/500 selected features: KCNN2\n",
            "475/500 selected features: NEUROG3\n",
            "476/500 selected features: LOC107985075\n",
            "477/500 selected features: FASLG\n",
            "478/500 selected features: LYG1\n",
            "479/500 selected features: JAKMIP1\n",
            "480/500 selected features: ZNF232-AS1\n",
            "481/500 selected features: ZNF114\n",
            "482/500 selected features: VWA3B\n",
            "483/500 selected features: CRTAM\n",
            "484/500 selected features: ACOXL\n",
            "485/500 selected features: KCNRG\n",
            "486/500 selected features: ALOX12B\n",
            "487/500 selected features: HOXD1\n",
            "488/500 selected features: CRYBA2\n",
            "489/500 selected features: M1AP\n",
            "490/500 selected features: CD164L2\n",
            "491/500 selected features: C6orf52\n",
            "492/500 selected features: IFNG\n",
            "493/500 selected features: KIR2DL4\n",
            "494/500 selected features: NBPF7\n",
            "495/500 selected features: HMSD\n",
            "496/500 selected features: MSH4\n",
            "497/500 selected features: LOC105371814\n",
            "498/500 selected features: ELOVL3\n",
            "499/500 selected features: HMX3\n",
            "500/500 selected features: TRDV1\n",
            "Selected Features:\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the estimator for RFE\n",
        "estimator=DecisionTreeClassifier()\n",
        "\n",
        "# Define the number of features to select\n",
        "n_features = 500\n",
        "\n",
        "# Perform RFE\n",
        "rfe = RFE(estimator, n_features_to_select=n_features)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = X_train.columns[rfe.support_]\n",
        "# Print the progress\n",
        "for i, feature in enumerate(selected_features):\n",
        "    print(f\"{i+1}/{len(selected_features)} selected features: {feature}\")\n",
        "\n",
        "print('Selected Features:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "IumqCtJBjKtx"
      },
      "outputs": [],
      "source": [
        "with open('selected_features from 33000 to 1000.txt', 'w') as f:\n",
        "    # Write the selected features to the file, separated by commas\n",
        "    f.write(','.join(selected_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "nesGSWloLef5"
      },
      "outputs": [],
      "source": [
        "X_train  =X_train.loc[:, X_train.columns.isin(selected_features)]\n",
        "X_test = X_test.loc[:, X_test.columns.isin(selected_features)]\n",
        "X_valid = X_valid.loc[:, X_valid.columns.isin(selected_features)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN_hmiXQ5tBl"
      },
      "source": [
        "try 500 from RFE top features, then RFM select top 200, and you train the RFM with the 200, to a new RFM and train and optimizing the hyperparameters of the RFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "DA92lv6INiiP",
        "outputId": "1d9720b9-6bef-4455-a8f4-287583244de8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as rf\n",
        "\n",
        "randomForest = rf()\n",
        "randomForest.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "importances = randomForest.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "top_200_indices = indices[:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_200 = X_train.iloc[:,top_200_indices]\n",
        "X_test_200 = X_test.iloc[:,top_200_indices]\n",
        "X_valid_200 = X_valid.iloc[:,top_200_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train_200.to_csv('X_train200.csv', index=False)\n",
        "X_test_200.to_csv('X_test200.csv', index=False)\n",
        "X_valid_200.to_csv('X_valid200.csv', index=False)\n",
        "y_train.to_csv('y_train1.csv', index=False)\n",
        "y_test.to_csv('y_test1.csv', index=False)\n",
        "y_valid.to_csv('y_valid1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_200=X_train_200.values\n",
        "X_train_200=X_train_200.astype(np.float32)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "dont run below this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "162\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.7206821480406387\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.48396226415094334\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7354136429608128\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8738751814223512\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8850507982583455\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9157474600870827\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9156748911465893\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.9539912917271408\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9387518142235123\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7666182873730043\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7333817126269956\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5601596516690857\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1000us/step\n",
            "Score: 0.8388969521044993\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.8004354136429608\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.843033381712627\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9120464441219157\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9386792452830189\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.896589259796807\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 996us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7895500725689405\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5026850507982583\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.41226415094339625\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8621915820029027\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "Score: 0.7196661828737301\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8122641509433961\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.854499274310595\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.9006531204644412\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9002902757619738\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7852685050798259\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "Score: 0.5342525399129172\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1000us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.6701741654571843\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8735123367198838\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.896589259796807\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.869956458635704\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.9232946298984034\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9234397677793904\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.9193759071117562\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6605224963715529\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6443396226415093\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7585631349782294\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.858055152394775\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8581277213352685\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1000us/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.86966618287373\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9044267053701016\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8698838896952104\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.881277213352685\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7814223512336719\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5944121915820029\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6012336719883888\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8280841799709723\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8851959361393323\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.904354136429608\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9042089985486212\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9618287373004355\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8428156748911466\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.4661828737300436\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.4603047895500726\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6433962264150944\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.7851233671988389\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8619738751814223\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8620464441219158\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8698838896952104\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 1s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8660377358490565\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8505805515239478\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6544267053701016\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7888243831640058\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.601378809869376\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5671262699564587\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8161103047895499\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.8467343976777938\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8583454281567489\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6583454281567489\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7123367198838897\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1000us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7396952104499275\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.5859941944847605\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8466618287373004\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.854499274310595\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.835123367198839\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 995us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8852685050798257\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8618287373004355\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.44462989840348327\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.7659651669085632\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6127721335268504\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7048621190130623\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.854499274310595\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8621190130624093\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8468069666182872\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.900145137880987\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "Score: 0.30297532656023224\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7428882438316402\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6753265602322206\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.7082728592162554\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8466618287373004\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8621190130624093\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8734397677793904\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.9350507982583455\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8389695210449928\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6623367198838896\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6658200290275762\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.5316400580551524\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7555152394775035\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8583454281567489\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.846734397677794\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.846589259796807\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8814223512336721\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'tanh'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8737300435413644\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "Score: 0.3031204644412192\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8468069666182874\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7627721335268505\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 999us/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5198838896952104\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 998us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8544267053701017\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8579825834542817\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.835123367198839\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8621915820029027\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (10,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 997us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8468069666182874\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.5648040638606677\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5622641509433963\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 996us/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5147314949201742\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6587082728592162\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.854499274310595\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.854499274310595\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8389695210449928\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (5,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.4929608127721335\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5621915820029029\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8160377358490567\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7506531204644412\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1000us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8506531204644412\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8506531204644412\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.6667634252539913\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (10, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.4262699564586357\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 998us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7275761973875181\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "Score: 0.8314949201741655\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5780841799709725\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8542815674891147\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8544267053701017\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8391146589259796\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8696661828737302\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8543541364296082\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5834542815674891\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6839622641509434\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8160377358490566\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 1000us/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.5698838896952104\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8542815674891147\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.5660377358490566\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20, 5), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.306821480406386\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 996us/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.8121915820029028\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.0001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.7108853410740203\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.3889695210449927\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "Score: 0.7108853410740203\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.001, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8505079825834543\n",
            "Evaluating params: {'optimizer': 'sgd', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.6852685050798258\n",
            "Evaluating params: {'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n",
            "Evaluating params: {'optimizer': 'RMSprop', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'sigmoid'}\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 3ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 2ms/step\n",
            "Score: 0.8429608127721335\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import ParameterSampler, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "\n",
        "# Define the hyperparameter grid to search over\n",
        "param_grid = {\n",
        "    'hidden_layers': [(10,), (5,),(10,5),(20,),(20,5),(20,10)],\n",
        "    'dropout_rate': [0.0],\n",
        "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
        "    'optimizer': ['sgd', 'adam', 'RMSprop',],\n",
        "    'learning_rate': [0.0001,0.001,0.01]\n",
        "    \n",
        "}\n",
        "\n",
        "# Define the number of hyperparameter combinations to sample\n",
        "n_iter = (len(param_grid['hidden_layers'])* len(param_grid['dropout_rate'])\n",
        "          *len(param_grid['activation'])*len(param_grid['optimizer'])*len(param_grid['learning_rate']))\n",
        "print(n_iter)\n",
        "\n",
        "# Sample hyperparameter combinations\n",
        "param_combinations = list(ParameterSampler(param_grid, n_iter=n_iter))\n",
        "\n",
        "# Define a function to build and compile a model given a set of hyperparameters\n",
        "def build_model(params):\n",
        "    model = tf.keras.Sequential()\n",
        "    for num_units in params['hidden_layers']:\n",
        "        model.add(tf.keras.layers.Dense(num_units, activation=params['activation']))\n",
        "        model.add(tf.keras.layers.Dropout(params['dropout_rate']))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    optimizer = tf.keras.optimizers.get(params['optimizer'])\n",
        "    optimizer.learning_rate = params['learning_rate']\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define a function to evaluate a model using cross-validation\n",
        "def evaluate_model(params, X_train, y_train):\n",
        "    k = 5\n",
        "    scores = []\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    for train_index, val_index in skf.split(X_train, y_train):\n",
        "        X_train_fold = X_train[train_index]\n",
        "        y_train_fold = y_train[train_index]\n",
        "        X_val_fold = X_train[val_index]\n",
        "        y_val_fold = y_train[val_index]\n",
        "        model = KerasClassifier(build_fn=build_model, params=params, verbose=0)\n",
        "        model.fit(X_train_fold, y_train_fold, epochs=5, batch_size=64)\n",
        "        y_val_pred = model.predict(X_val_fold)\n",
        "        score = accuracy_score(y_val_fold, y_val_pred)\n",
        "        scores.append(score)\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Evaluate each hyperparameter combination using cross-validation\n",
        "best_score = 0\n",
        "best_params = None\n",
        "scores_and_param=[]\n",
        "import time\n",
        "start_time = time.time()\n",
        "for params in param_combinations:\n",
        "    print(f'Evaluating params: {params}')\n",
        "    score = evaluate_model(params, X_train_200, y_train)    \n",
        "    scores_and_param.append(params)\n",
        "    scores_and_param.append(score)\n",
        "    print(f'Score: {score}')\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_params = params\n",
        "end_time = time.time()\n",
        "import warnings\n",
        "warnings.resetwarnings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20, 10), 'dropout_rate': 0.0, 'activation': 'relu'}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>hidden_layers</th>\n",
              "      <th>dropout_rate</th>\n",
              "      <th>activation</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>adam</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>(20, 10)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.961829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>adam</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.953991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.938752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>adam</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>(5,)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.938679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>adam</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>(20, 5)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.935051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>(10, 5)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.412264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>(20, 10)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.388970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>(20, 10)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.306821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.303120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>sgd</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>(20, 5)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.302975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    optimizer  learning_rate hidden_layers  dropout_rate activation     score\n",
              "52       adam         0.0100      (20, 10)           0.0       relu  0.961829\n",
              "7        adam         0.0100         (10,)           0.0       relu  0.953991\n",
              "8     RMSprop         0.0100         (10,)           0.0       relu  0.938752\n",
              "16       adam         0.0100          (5,)           0.0       relu  0.938679\n",
              "97       adam         0.0100       (20, 5)           0.0       tanh  0.935051\n",
              "..        ...            ...           ...           ...        ...       ...\n",
              "20    RMSprop         0.0001       (10, 5)           0.0       relu  0.412264\n",
              "156       sgd         0.0010      (20, 10)           0.0    sigmoid  0.388970\n",
              "153       sgd         0.0001      (20, 10)           0.0    sigmoid  0.306821\n",
              "108       sgd         0.0001         (10,)           0.0    sigmoid  0.303120\n",
              "90        sgd         0.0001       (20, 5)           0.0       tanh  0.302975\n",
              "\n",
              "[162 rows x 6 columns]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(best_params)\n",
        "data = []\n",
        "for i in range(0, len(scores_and_param), 2):\n",
        "    row = scores_and_param[i].copy()\n",
        "    row['score'] = scores_and_param[i+1]\n",
        "    data.append(row)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.sort_values(by='score', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the scores from your list\n",
        "scores = [item for item in scores_and_param if isinstance(item, float)]\n",
        "\n",
        "# Sample hyperparameter combinations and evaluate them using cross-validation\n",
        "\n",
        "\n",
        "# Calculate the mean and standard deviation of the validation scores for each hyperparameter combination\n",
        "means = np.mean(scores, axis=1)\n",
        "stds = np.std(scores, axis=1)\n",
        "\n",
        "# Create a bar chart with error bars\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(np.arange(len(param_combinations)), means, yerr=stds, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xticks(np.arange(len(param_combinations)))\n",
        "ax.set_xticklabels([str(params) for params in param_combinations], rotation='vertical')\n",
        "ax.set_title('Validation scores for different hyperparameter settings')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#best_params={'optimizer': 'adam', 'learning_rate': 0.01, 'hidden_layers': (20,), 'dropout_rate': 0.0, 'activation': 'relu'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Build and train a new model using the best hyperparameters\n",
        "best_model = build_model(best_params)\n",
        "history = best_model.fit(X_train_200.astype(np.float32), y_train.astype(np.float32), \n",
        "                          epochs=20,validation_data=(X_valid_200.astype(np.float32), y_valid.astype(np.float32)),verbose=0)\n",
        "# Plot the accuracy and validation accuracy over the epochs\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Predict probabilities on the test set\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "y_pred_prob = best_model.predict(X_test_200.astype(np.float32))\n",
        "\n",
        "# Calculate false positive rate, true positive rate, and threshold values for ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "\n",
        "# Calculate AUC score\n",
        "auc_score = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Plot')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
